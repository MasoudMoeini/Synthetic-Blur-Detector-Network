{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4Z2ZAVCAv6fKWXnee1vvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasoudMoeini/Synthetic-Blur-Detector-Network/blob/main/NewNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bo85VTQUOkq3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from keras.optimizers import gradient_descent_v2 \n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq label.zip"
      ],
      "metadata": {
        "id": "H2IcEKO_MRHm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq Blur.zip"
      ],
      "metadata": {
        "id": "deg52ICyMhsR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from numpy import *\n",
        "train = []\n",
        "files = glob.glob (\"Blur/*.jpg\")\n",
        "for myFile in files:\n",
        "    image = array(Image.open(myFile))\n",
        "    train.append (image)\n",
        "train = np.array(train) \n",
        "train= np.reshape(train,[train.shape[0],train.shape[1],train.shape[2],train.shape[3]])\n",
        "np.save('train-blur-images',train)"
      ],
      "metadata": {
        "id": "QVB93OLAM8Dq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = []\n",
        "files = glob.glob (\"label/*.jpg\")\n",
        "for myFile in files:\n",
        "    image = array(Image.open(myFile))\n",
        "    label.append (image)\n",
        "label = np.array(label) \n",
        "label= np.reshape(label,[train.shape[0],label.shape[1],label.shape[2],label.shape[3]])\n",
        "np.save('label-images',label)"
      ],
      "metadata": {
        "id": "i1XbXI4IOBHv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "   \n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])# SKIP Connection\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "005EywP_Ospa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "8yntxHhWPLuQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50():\n",
        "    #X_input = keras.Input(shape=input_shape)\n",
        "    X_input = layers.Input(shape=(224, 224, 3))\n",
        "    #X = data_augmentation(X_input)\n",
        "    #X = layers.Rescaling(1./255)(X)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "    \n",
        "    #4*4*2048\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = Dense(147, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    #X = Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    #X = Dense( 1,activation='sigmoid', name='fc3',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    #decoder\n",
        "    x = keras.layers.Reshape([7,7,3])(X)\n",
        "    x = layers.Conv2DTranspose(3, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(3, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(3, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(3, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(3, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    #x = layers.Conv2DTranspose(3, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(3, (3, 3), strides=1, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "    output = layers.Conv2DTranspose(3, (3, 3), strides=1, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "    model = Model(inputs=X_input, outputs=output , name='ResNet50')\n",
        "    return model"
      ],
      "metadata": {
        "id": "FqFA32fePQxA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50()\n",
        "#keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "FoKuO6syZZ5j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(keras.optimizers.Adam(learning_rate=0.001),\n",
        "                        loss=tf.keras.losses.BinaryCrossentropy(),)\n"
      ],
      "metadata": {
        "id": "RmSSFP3nawsK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.load('train-blur-images.npy')\n",
        "y_train = np.load('label-images.npy')\n",
        "x_train = x_train.astype(np.float32)/ 255.0\n",
        "y_train = y_train.astype(np.float32)/ 255.0"
      ],
      "metadata": {
        "id": "__UqXQ1nPQrA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.summary()"
      ],
      "metadata": {
        "id": "Lkp50ukZbZ3C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Optimize\n",
        "history = model.fit(x_train,y_train, epochs=15,batch_size=50, validation_split=0.2, shuffle=True)\n",
        "model.save('new_model.h5')"
      ],
      "metadata": {
        "id": "7hU5AzP4bC3s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}